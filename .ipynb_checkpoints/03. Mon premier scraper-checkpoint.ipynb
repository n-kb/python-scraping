{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Mon premier scraper\n",
    "\n",
    "Dans ce cours: \n",
    "- L'architecture client/serveur\n",
    "- Récupérer le contenu d'une page avec request\n",
    "- Parser une page HTML avec BeautifulSoup\n",
    "- Exporter le résultat au format CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python permet d'importer des modules.\n",
    "# Les modules sont souvent des librairies contenant en tas de fonctions utiles \n",
    "# pour diverses tâches (analyse de données, visualisations... et scraping)\n",
    "\n",
    "# Requests est l'une des librairies utilisées pour faire des requêtes HTTP\n",
    "# Documentation: http://docs.python-requests.org/en/master/user/quickstart/\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L'URL à extraire\n",
    "url = \"https://www.leboncoin.fr/materiel_agricole/\"\n",
    "\n",
    "# la variable r est un objet de type \"requests\". \n",
    "# Un objet est un type de variable nouveau, qui a des méthodes et des propriétés\n",
    "r = requests.get(url)\n",
    "\n",
    "# \"text\" est par exemple une propriété des objets \"requests\"\n",
    "# \"status_code\" en est une autre.\n",
    "print(r.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.text)\n",
    "\n",
    "# Découverte du HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup est une librairie qui permet de \"parser\" le HTML\n",
    "# Parser = \"faire l'analyse gramaticale de\" en anglais, même racine que \"part\"\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comme on a créé un objet de type \"requests\" tout à l'heure,\n",
    "# on créer un objet de type \"BeautifulSoup\".\n",
    "# Pour créer cet objet, on l'initialise avec deux paramètres: une chaîne de caractère et le type de HTML à parser.\n",
    "\n",
    "soup = BeautifulSoup(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les Soup ont des méthodes très pratique. Par exemple: find_all\n",
    "# find_all prend un paramètre: le type de balise HTML que l'on cherche\n",
    "# et il nous retourne une liste contenant tous ces éléments\n",
    "\n",
    "soup.find_all(\"li\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il faut maintenant trouver un moyen d'extraire uniquement les éléments qui nous intéressent.\n",
    "\n",
    "# Pour les matériels agricoles, on remarque que chaque annonce est un élément <a> avec la classe \"list_item\"\n",
    "\n",
    "# Pour sélectionner uniquement les élements ayant une certaine classe, on fait:\n",
    "\n",
    "soup.find_all(\"a\", {\"class\": \"list_item\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Au sein de chaque élément, essayons maintenant d'extraire le titre de l'annonce\n",
    "\n",
    "annonces = soup.find_all(\"a\", {\"class\": \"list_item\"})\n",
    "\n",
    "# Une boucle qui passe en revue toutes les annonces\n",
    "for annonce in annonces:\n",
    "    # La variable \"annonce\" est aussi une Soup! On peut utiliser les mêmes méthodes que sur la Soup parente.\n",
    "    # Lorsque l'on sait que l'on cherche un seul élément, on utilise find au lieu de find_all\n",
    "    print (annonce.find(\"h2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for annonce in annonces:\n",
    "    # La propriété text retourne uniquement le texte contenu à l'intérieur d'un élément HTML\n",
    "    print (annonce.find(\"h2\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for annonce in annonces:\n",
    "    # La méthode strip() permet de supprimer les espaces en début et fin d'une chaîne de caractères\n",
    "    print (annonce.find(\"h2\").text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Petit débug: Pourquoi avons-nous ces messages d'erreur?\n",
    "\n",
    "\n",
    "\n",
    "# ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une solution possible:\n",
    "\n",
    "annonces = soup.find(\"section\", {\"class\": \"tabsContent\"}).find_all(\"a\", {\"class\": \"list_item\"})\n",
    "for annonce in annonces:\n",
    "    print (annonce.find(\"h2\").text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On utilise depuis quelques temps le _chaînage_ des méthodes\n",
    "# On pourrait écrire la même chose avec des variables intermédiaires\n",
    "\n",
    "section_principale = soup.find(\"section\", {\"class\": \"tabsContent\"})\n",
    "annonces = section_principale.find_all(\"a\", {\"class\": \"list_item\"})\n",
    "\n",
    "\n",
    "for annonce in annonces:\n",
    "    titre_de_lannonce_HTML = annonce.find(\"h2\")\n",
    "    titre_de_lannonce_texte = titre_de_lannonce_HTML.text\n",
    "    titre_de_lannonce_texte_propre = titre_de_lannonce_texte.strip()\n",
    "    print (titre_de_lannonce_texte_propre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice: Parser du HTML\n",
    "# Extrayez maintenant le prix de chaque annonce\n",
    "\n",
    "for annonce in annonces:\n",
    "    titre = annonce.find(\"h2\").text.strip()\n",
    "    prix = ???\n",
    "    print (titre, prix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut aussi sélectionner les élément HTML via leurs autres propriétés\n",
    "\n",
    "for annonce in annonces:\n",
    "    titre = annonce.find(\"h2\").text.strip()\n",
    "    lieu = annonce.find(\"p\", {\"itemtype\": \"http://schema.org/Place\"}).text.strip()\n",
    "    print (titre, lieu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C'est le moment de voir une nouvelle méthode des chaînes de caractères: split()\n",
    "# Split retourne une liste des chaînes de caractères présentes de chaque côté du séparateur\n",
    "\n",
    "for annonce in annonces:\n",
    "    titre = annonce.find(\"h2\").text.strip()\n",
    "    lieu = annonce.find(\"p\", {\"itemtype\": \"http://schema.org/Place\"}).text.strip()\n",
    "    print (lieu.split(\"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for annonce in annonces:\n",
    "    titre = annonce.find(\"h2\").text.strip()\n",
    "    lieu = annonce.find(\"p\", {\"itemtype\": \"http://schema.org/Place\"}).text.strip()\n",
    "    commune = lieu.split(\"/\")[0].strip()\n",
    "    département = lieu.split(\"/\")[1].strip()\n",
    "    print (titre, commune, département)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegardons maintenant le tout dans un fichier CSV\n",
    "\n",
    "# On créé une liste vide contenant les données à enregistrer\n",
    "\n",
    "data = []\n",
    "\n",
    "for annonce in annonces:\n",
    "    titre = annonce.find(\"h2\").text.strip()\n",
    "    lieu = annonce.find(\"p\", {\"itemtype\": \"http://schema.org/Place\"}).text.strip()\n",
    "    commune = lieu.split(\"/\")[0].strip()\n",
    "    département = lieu.split(\"/\")[1].strip()\n",
    "    \n",
    "    # On créé un dictionnaire contenant les données de chaque annonce\n",
    "    item = {\"titre\": titre, \"commune\": commune, \"département\": département}\n",
    "    \n",
    "    # On utilise la méthode \"append\" pour rajouter notre dict à la liste\n",
    "    data.append(item)\n",
    "    \n",
    "# On importe maintenant le module CSV\n",
    "\n",
    "import csv\n",
    "\n",
    "keys = data[0].keys()\n",
    "with open('data_agricole.csv', 'w') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice: \n",
    "# Dans un nouveau notebook, scraper, parser et enregistrer les offres de la catégorie \"Informatique\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
